ğŸš€ Serverless DevOps Log Analysis Agent (RAG + AWS + Gemini AI)

A fully serverless, production-ready Log Analysis Agent built on AWS + LangGraph + Google Gemini.
This system ingests logs, converts them into searchable vectors, retrieves the most relevant chunks, validates them using an AI grader, and finally produces actionable insights â€” all without managing servers.

â­ Key Features
ğŸ”¥ 1. End-to-End Serverless Architecture

Fully deployed using AWS Lambda, S3, CloudWatch, API Gateway, and ECR.

Zero maintenance, auto-scalable, cost-efficient.

ğŸ¤– 2. Dual AI Agents (LangGraph)

Ingest Worker Agent:
Processes logs uploaded to S3 â†’ cleans â†’ chunks â†’ embeds â†’ stores into FAISS vector DB.

Chat Retrieval Agent:
Accepts user queries â†’ retrieves relevant log chunks â†’ grades relevance â†’ answers using Gemini AI.

ğŸ§  3. RAG (Retrieval-Augmented Generation) Pipeline

FAISS Vector Search

Node Retrieval Agent (Retriever)

Node Grading Agent (Relevance Checker)

Best-result answer generator (Gemini)

ğŸ“¦ 4. Infrastructure as Code

Entire cloud infra deployed via Terraform (one command).

ğŸ’¬ 5. Streamlit Frontend

Clean chat UI

.
â”œâ”€â”€ aws_cloud/            # Terraform Infrastructure code
â”‚   â”œâ”€â”€ lambda.tf         # Chat & Ingest functions infra
â”‚   â”œâ”€â”€ s3.tf             # S3 bucket + event triggers
â”‚   â”œâ”€â”€ iam.tf            # IAM roles for Lambda
â”‚   â”œâ”€â”€ ecr.tf            # ECR repo for containerized Lambda
â”‚   â””â”€â”€ variables.tf
â”‚
â”œâ”€â”€ backend/              # Python Source Code
â”‚   â”œâ”€â”€ agent.py          # LangGraph RAG pipeline (Chat bot)
â”‚   â”œâ”€â”€ ingest.py         # Log processor + FAISS vector creator
â”‚   â”œâ”€â”€ Dockerfile        # Containerized Lambda image
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend/             # Streamlit Web UI
    â”œâ”€â”€ app.py            # Chat Interface
    â””â”€â”€ styles.css


ğŸš€ Deployment Guide
Step 1 â€” Clone Repository
git clone https://github.com/<your-repo>/log-analysis-rag-agent.git
cd log-analysis-rag-agent

Step 2 â€” Deploy AWS Resources
cd aws_cloud
terraform init
terraform apply

Step 3 â€” Build & Push Lambda Docker Image
cd backend
docker build -t log-agent .
aws ecr get-login-password | docker login ...
docker tag log-agent:latest <AWS_ACCOUNT>.dkr.ecr.<region>.amazonaws.com/log-agent
docker push <AWS_ECR_URL>

Step 4 â€” Run Frontend Locally
cd frontend
pip install -r ../backend/requirements.txt
streamlit run app.py
Sends POST request â†’ triggers AWS Lambda â†’ returns generated solution with logs context.
